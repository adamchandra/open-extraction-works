
** Feature Agenda

   - [ ] Bulk-add AlphaRecords to system (REST/CLI)
     * put recs in AlphaRecs.Inbox

   - [ ] Run Spider/Extractor in background

     AlphaRecs.Inbox -> Lock.Spider
     Lock.Spider -> Spider.
   - [ ] Update code and re-run everything
   - [ ] Overview webpage detailing:
     - All Extracted Fields/Urls/Domains
     - State of Spider, extractor
     - Means to input single Url/AlphaRecord
     - [ ] Means to mark extracted field as correct/incorrect
       - [ ] Create GroundTruth files/db table(s)



*** Path structure
    * Group records into sets according to conference
    AlphaRec.Group.G23
    * Ground-truth labeling, per field/url
      ground-truth.(in)correct
      ground-truth.

** Database Structure

   AlphaRecord      [id, noteId, url, dblpKey, authorId, title]
   UrlChain         [requestUrl, responseUrl, statusCode]
   ExtractedField   [alphaRecordId, name, value]

   AlphaRecord -1-1-> UrlChain
   AlphaRecord -1-*-> ExtractedField


** Development
*** Building
    > lerna bootstrap

*** Checking/Updating node_module dependency versions
    > npm run deps:check
    > npm run deps:update


** Deployment

** TODO building/running/deploying Docker
   Volume setup (corpus files, database files)
   TODO change docker images from adamchandra/* to iesl or openreview or something else

*** Build docker image
    > docker/bin/build-images.sh


*** Docker up/down/restart
    > docker/bin/docker-up.sh
    > docker/bin/docker-down.sh

    Restart is docker-down + build-images + docker-up
    > docker/bin/docker-restart.sh


*** Running docker on production host

    IMAGE=adamchandra/service-portal
    APP_SHARE_PATH=~/app-share.d/
    APP_SHARE_MOUNT=/usr/src/app/

    docker run --name=$IMAGE -d -v $APP_SHARE_PATH:$APP_SHARE_MOUNT nginx $IMAGE

    docker run --name=adamchandra/service-portal -d -v ~/nginxlogs:/var/log/nginx -p 5000:80 nginx

*** Mapping users on production host to user running services inside docker
    Given that our system generates many files (spider downloads, extraction results), it is convenient
    to have those files owned by the user that is running the docker container, rather than a  user that
    exists only within Docker, or by root.

    The technique to do this is outlined here:
    https://jtreminio.com/blog/running-docker-containers-as-current-host-user/#ok-so-what-actually-works



*** Usage Scenarios:
**** Seeing a faulty extracted abstract and needing to report/correct it
**** Viewing overview/stats:
*****  # of abstracts available for a reviewer candidate
**** Downloading the json with all extracted fields
