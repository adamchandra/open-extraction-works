
* Textworks as a service
   
** Usage Overview

*** Q/A Workflow
**** Collecting stats
     yarn workspace textworks-aas corpus collect-stats --cwd=../../orc.d --corpus-root=corpus.d --logfile logs.d/qa-write-abstracts.json
     
     
** Subsystems
   
*** REST Ingress
    - listen for CSV inputs
    - filter out already spidered/extracted URLs
    - write out spidering-urls.csv
    - respond via REST with results and/or status
      

*** Spider/Scraper
    - Targeted scraping of explicit URLs
    - Spidering done with either Scrapy, browser (via selenium), or axios
    - Uses ELK to filter it's scraping (to avoid re-spidering 301/2 before getting to cached files)
    - log output to ELK to register completed spidering files
    
*** HTML field extractor
    Current recognized fields: Abstracts (next up: PDF urls)

*** Corpus Management
    Hierarchical directory structuring with hashed-prefix paths

**** Corpus Artifacts
    
*** Extraction Q/A Editing
    Review extraction choices and interactively approve or mark errors 

** Pipeline structure
   
*** Input: NoteId,url,dbplId 
    H1ZqgCxO-S,
    dblp.org/conf/AAAI/2018,
    https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16391
   
   [Order: csv/json w/noteId,url,..] -> Inbox
   
*** OpenReview Module:
**** DB Structure
     - Orders: [OrderId, Source, orderDate, lastModDate] where Source is the original CSV or JSON
       Keep track of the original request 

     - OrderPart: [OrderId, OrderPartId, PartRec(Json)]
       Record the 'actionable' parts of the order, i.e., those that can be operated individually
       PartRec: { noteId }
   
     - OrderPartFulfillment: [OrderPartId, FulfillmentStateRadios, FulfillmentRec(Json)]
   
       FulfillmentRec: { fields: [{ name: 'abstract', value: 'Abs... '}]}
       FulfillmentRec: { $fileTicketId: 'az-Kj' } <- pointer to an artifactId understood by the Corpus
       FulfillmentRec: { } <-
       FulfillmentStateRadios: in




   Finale: noteId -> (field:abstract, field:pdfUrl) 
